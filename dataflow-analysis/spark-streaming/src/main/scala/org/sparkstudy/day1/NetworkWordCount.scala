package org.sparkstudy.day1

import org.apache.spark.SparkConf
import org.apache.spark.storage.StorageLevel
import org.apache.spark.streaming.{Seconds, StreamingContext}

/**
  * 1.0 A Quick Example
  *
  * Let’s say we want to count the number of words in text data received from a data server listening on a TCP socket
  *
  * Scala的函数与类型转换系统是难点，需要加强练习。
  * 函数:
  * 函数传名调用(Call-by-Name),	指定函数参数名
  * 函数-可变参数, 递归函数
  * 默认参数值, 高阶函数
  * 内嵌函数, 匿名函数
  * 偏应用函数, 函数柯里化(Function Currying)
  *
  * Scala语法点: 1、匿名函数 '参数列表 => 函数体' :
  *               Scala 中定义匿名函数的语法很简单，箭头左边是参数列表，右边是函数体，参数的类型是可省略的，
  *               Scala 的类型推测系统会推测出参数的类型。使用匿名函数后，我们的代码变得更简洁了。
  *             2、隐式转换 'implicit':
  *             参考: https://www.jianshu.com/p/1d119c937015
  *             Scala在面对编译出现类型错误时，提供了一个由编译器自我修复的机制，编译器试图去寻找
  *             一个隐式implicit的转换方法，转换出正确的类型，完成编译。这就是implicit 的意义。
  *             reduceByKey 采用隐身转换.
  *
  * Link: http://spark.apachecn.org/docs/cn/2.2.0/streaming-programming-guide.html
  *
  *
  */
object NetworkWordCount {

  def main(args: Array[String]): Unit = {

    // org.sparkstudy.day1.NetworkWordCount localhost 9999
    if (args.length < 2) {
      System.err.printf("Usage: NetworkWordCount <hostname> <port>")
      System.exit(1)
    }

    val sparkConf = new SparkConf()
    sparkConf.setAppName("NetworkWordCount")
    sparkConf.setMaster("local[2]")
    // create the context with a 1 second batch size
    val ssc = new StreamingContext(sparkConf, Seconds(1))

    // Create a socket stream on target ip:port and count the
    // words in input stream of \n delimited text (eg. generated by 'nc')
    // Note that no duplication in storage level only for running locally.
    // Replication necessary in distributed scenario for fault tolerance.
    val lines = ssc.socketTextStream(args(0), args(1).toInt, StorageLevel.MEMORY_AND_DISK_SER)
    val words = lines.flatMap(_.split(" "))
    /** Return a new DStream by applying a function to all elements of this DStream. */
    val wordMaps = words.map(x => (x, 1))
    /**
      * Extra functions available on DStream of (key, value) pairs through an implicit conversion.
      *
      * implicit conversion is passed my understanding, I don't like!
      */
    val wordCounts = wordMaps.reduceByKey(_ + _)

    wordCounts.print()

    ssc.start()
    ssc.awaitTermination()
  }

}
